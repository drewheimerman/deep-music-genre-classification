# Deep Music Genre Classification
Using deep learning to categorize music as time progresses through dpectrogram snalysis.

## About
Our aim is to create a neural network (CNN + LSTM RNN) that recognizes music genre and provides a user-friendly visualization for the network's current belief of the genre of a song.

This project uses Keras, using TensorFlow for the backend, for the neural network and Tornado for serving requests.

## Background
The rationale for this particular model is based on several works, primarily [Grzegorz Gwardys and Daniel Grzywczak, Deep Image Features in Music Information Retrieval](http://ijet.pl/index.php/ijet/article/view/10.2478-eletel-2014-0042/53), [Recommending music on Spotify with Deep Learning](http://benanne.github.io/2014/08/05/spotify-cnns.html), and [Convolutional-Recurrent Neural Network for Live Music Genre Recognition](http://deepsound.io/music_genre_recognition.html).  

# Paper

Our paper can be located here: (./Music_Genre_Recognition-3.pdf)

## Data
### Spectrogram Representation

Mel-spectrograms were generated using the Librosa python library. Number of FFTs was set to 2048 and the number of mels was 128.

### Dataset
TODO


## Model
### Motivation
TODO

### Architecture
TODO


## Results
### Summary Statistics
TODO

### Conclusion
TODO


## Demo
TODO


## Usage
TODO


## Slides
The slide deck can be found on Google Slides: [Using Deep Learning to Categorize Music as Time Progresses Through Spectrogram Analysis](https://docs.google.com/presentation/d/1MANAML13S-PBGx8bsbI8gdaKGPJ2bPd_UNbA3E2txdg/edit?usp=sharing).
